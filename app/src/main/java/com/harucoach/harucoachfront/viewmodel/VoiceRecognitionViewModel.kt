package com.harucoach.harucoachfront.viewmodel

import android.app.Application
import android.content.Intent
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.util.Log
import androidx.compose.runtime.mutableStateOf
import androidx.lifecycle.AndroidViewModel
import kotlinx.coroutines.*
import java.util.Locale

class VoiceRecognitionViewModel(application: Application) : AndroidViewModel(application) {

    private val context = application.applicationContext

    var recordedText = mutableStateOf("")
    var errorMessage = mutableStateOf("")
    var isListening = mutableStateOf(false)
    var btnState = mutableStateOf(1) // 1=ë§í•˜ê¸°, 2=ëŒ€ê¸°, 3=ì¢…ë£Œ

    private var speechRecognizer: SpeechRecognizer? = null
    private var tts: TextToSpeech? = null
    private val coroutineScope = CoroutineScope(Dispatchers.Main)

    private val speechRecognizerIntent: Intent by lazy {
        Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, context.packageName)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault().toLanguageTag())
            //putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS, 3000)
            //putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS, 3000)
            //putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS, 10000)
        }
    }

    init {
        setupSpeechRecognizer()
        setupTTS()
    }

    private fun setupSpeechRecognizer() {
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(context).apply {
            setRecognitionListener(object : RecognitionListener {
                override fun onReadyForSpeech(params: Bundle?) {
                    Log.d("STT", "ğŸ¤ onReadyForSpeech")
                    errorMessage.value = ""
                    isListening.value = true
                }

                override fun onBeginningOfSpeech() {
                    Log.d("STT", "ğŸ™ï¸ ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘")
                }

                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray?) {}
                override fun onEndOfSpeech() {
                    Log.d("STT", "ğŸ›‘ onEndOfSpeech")
                }

                override fun onError(error: Int) {
                    isListening.value = false
                    val msg = when (error) {
                        SpeechRecognizer.ERROR_AUDIO -> "ì˜¤ë””ì˜¤ ì˜¤ë¥˜"
                        SpeechRecognizer.ERROR_CLIENT -> "í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜"
                        SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "ê¶Œí•œ ë¶€ì¡±"
                        SpeechRecognizer.ERROR_NETWORK -> "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜"
                        SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ë„¤íŠ¸ì›Œí¬ ì‹œê°„ ì´ˆê³¼"
                        SpeechRecognizer.ERROR_NO_MATCH -> "ì¼ì¹˜í•˜ëŠ” ê²°ê³¼ ì—†ìŒ"
                        SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "ìŒì„± ì¸ì‹ê¸° ì‚¬ìš© ì¤‘"
                        SpeechRecognizer.ERROR_SERVER -> "ì„œë²„ ì˜¤ë¥˜"
                        SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "ì…ë ¥ ì‹œê°„ ì´ˆê³¼"
                        else -> "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: $error"
                    }
                    errorMessage.value = msg
                    Log.e("STT", "âŒ $msg")
                }

                override fun onResults(results: Bundle?) {
                    val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    if (!matches.isNullOrEmpty()) {
                        recordedText.value = matches[0]
                        Log.d("STT", "âœ… ì¸ì‹ ê²°ê³¼: ${matches[0]}")

                        // ğŸ‘‡ 0.3ì´ˆ ì§€ì—° í›„ btnState ë³€ê²½ (UI ì•ˆì „í•˜ê²Œ ë¦¬ì»´í¬ì¦ˆ)
                        coroutineScope.launch {
                            delay(300)
                            btnState.value = 3
                            isListening.value = false
                        }
                    }
                }

                override fun onPartialResults(partialResults: Bundle?) {
                    val matches = partialResults?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    if (!matches.isNullOrEmpty()) {
                        recordedText.value = matches[0]
                    }
                }

                override fun onEvent(eventType: Int, params: Bundle?) {}
            })
        }
    }

    private fun setupTTS() {
        tts = TextToSpeech(context) { status ->
            if (status == TextToSpeech.SUCCESS) {
                tts?.language = Locale.KOREAN
                Log.d("TTS", "âœ… ì´ˆê¸°í™” ì™„ë£Œ")
            } else {
                Log.e("TTS", "âŒ ì´ˆê¸°í™” ì‹¤íŒ¨")
            }
        }
    }

    fun startListening() {
        Log.d("STT", "ğŸ¤ startListening í˜¸ì¶œë¨")
        recordedText.value = ""
        isListening.value = true
        errorMessage.value = ""
        speechRecognizer?.startListening(speechRecognizerIntent)
    }

    fun stopListening() {
        Log.d("STT", "ğŸ›‘ stopListening í˜¸ì¶œë¨")
        isListening.value = false
        speechRecognizer?.stopListening()
    }

    fun speak(text: String) {
        tts?.speak(text, TextToSpeech.QUEUE_FLUSH, null, "tts_id")
    }

    override fun onCleared() {
        super.onCleared()
        speechRecognizer?.destroy()
        tts?.stop()
        tts?.shutdown()
    }
}
